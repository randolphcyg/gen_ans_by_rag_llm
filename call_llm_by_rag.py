import logging
import requests
import torch
import jieba
from typing import List, Dict
from sentence_transformers import CrossEncoder
from pymilvus import MilvusClient
from stopwords import StopWordsManager

# ===================== æ ¸å¿ƒé…ç½® =====================
MILVUS_URI = "http://localhost:19530"
COLLECTION_NAME = "zeek_rag_v8_0_4"
OLLAMA_HOST = "http://localhost:11434"
EMBED_MODEL = "bge-m3:latest"
LLM_MODEL = "qwen2.5-coder:3b"

# æ£€ç´¢ä¸é‡æ’é…ç½®
RETRIEVE_TOP_K = 50
RERANK_TOP_K = 3
RRF_K = 60  # RRFç®—æ³•å‚æ•°

class ZeekRAGAssistant:
    def __init__(self):
        self.stop_words_manager = StopWordsManager()
        jieba.initialize()  # æ˜¾å¼åˆå§‹åŒ–

        try:
            self.milvus_client = MilvusClient(uri=MILVUS_URI)
            device = "cuda" if torch.cuda.is_available() else "cpu"
            # å¼ºåˆ¶ Reranker ä½¿ç”¨ CPU ä»¥èŠ‚çœæ˜¾å­˜ç»™ LLM
            self.reranker = CrossEncoder('BAAI/bge-reranker-base', device=device)
            logging.info(f"âœ… åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ | Reranker: CPU | LLM: {LLM_MODEL}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def get_embedding(self, text: str):
        """è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼ˆå¢åŠ å¼‚å¸¸å¤„ç†ï¼‰"""
        try:
            resp = requests.post(f"{OLLAMA_HOST}/api/embed",
                                 json={"model": EMBED_MODEL, "input": [text]}, timeout=10)
            return resp.json()["embeddings"][0]
        except: return None

    def retrieve(self, query: str):
        # 1. è¯­ä¹‰æ£€ç´¢
        query_vec = self.get_embedding(query)
        v_hits = []
        if query_vec:
            res = self.milvus_client.search(
                collection_name=COLLECTION_NAME, data=[query_vec],
                limit=RETRIEVE_TOP_K, output_fields=["doc_title", "section_title", "raw_content", "content_type"]
            )
            v_hits = [hit["entity"] for hit in res[0]]

        # 2. å¢å¼ºå…³é”®è¯æ£€ç´¢
        k_hits = []
        # è¿™é‡Œçš„å…³é”®è¯æå–ç°åœ¨èƒ½ä¿ç•™ zeek_init
        keywords = self.stop_words_manager.filter_stop_words(query)

        # å…œåº•ç­–ç•¥ï¼šå¦‚æœåˆ†è¯æ²¡åˆ†å‡ºç»“æœï¼Œç›´æ¥æ‹¿æ•´ä¸ª query åšæ¨¡ç³ŠåŒ¹é…
        if not keywords: keywords = [query.strip()]

        filter_exprs = []
        for kw in keywords[:5]: # é™åˆ¶è¯æ•°æé«˜æ€§èƒ½
            filter_exprs.append(f'section_title like "%{kw}%"')
            filter_exprs.append(f'raw_content like "%{kw}%"')

        if filter_exprs:
            k_res = self.milvus_client.query(
                collection_name=COLLECTION_NAME,
                filter=" or ".join(filter_exprs),
                limit=RETRIEVE_TOP_K,
                output_fields=["doc_title", "section_title", "raw_content", "content_type"]
            )
            k_hits = k_res

        return self.reciprocal_rank_fusion(v_hits, k_hits)

    def reciprocal_rank_fusion(self, v_hits, k_hits):
        scores = {}
        doc_map = {}
        for rank, h in enumerate(v_hits):
            key = h["raw_content"][:200]
            scores[key] = scores.get(key, 0) + 1.0 / (RRF_K + rank + 1)
            doc_map[key] = h
        for rank, h in enumerate(k_hits):
            key = h["raw_content"][:200]
            scores[key] = scores.get(key, 0) + 1.0 / (RRF_K + rank + 1)
            doc_map[key] = h

        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [doc_map[k] for k, s in sorted_docs[:30]]

    def rerank_with_bge(self, query: str, hits: List[Dict]):
        if not hits: return []

        # è¯„åˆ†å‰è¿‡æ»¤ï¼Œç¡®ä¿åŒ…å«å…·ä½“å‡½æ•°å/å­—æ®µåçš„åˆ‡ç‰‡æ’åœ¨å‰é¢
        query_lower = query.lower()
        pairs = [[query, h["raw_content"][:800]] for h in hits]
        bge_scores = self.reranker.predict(pairs)

        for i, hit in enumerate(hits):
            base = float(bge_scores[i])
            boost = 0.0
            title = hit.get("section_title", "").lower()

            # ç­–ç•¥ A: æ ‡é¢˜å…³é”®è¯å¯†åº¦
            q_words = set(self.stop_words_manager.filter_stop_words(query, 1))
            t_words = set(self.stop_words_manager.filter_stop_words(title, 1))
            if q_words.intersection(t_words):
                boost += 25.0

            # ç­–ç•¥ B: ç»“æ„åŒ–å¥–åŠ±
            if ">" in title: boost += 10.0

            # ç­–ç•¥ C: æŠ€æœ¯æ„å›¾å¥–åŠ± (é’ˆå¯¹ client_cert, zeek_init ç­‰)
            if any(term in query_lower for term in ["cert", "init", "done", "log", "å­—æ®µ"]):
                if any(term in title for term in ["base", "script", "reference", "manual"]):
                    boost += 15.0

            hit["base_score"] = base
            hit["boost"] = boost
            hit["final_score"] = base + boost

        return sorted(hits, key=lambda x: x["final_score"], reverse=True)[:RERANK_TOP_K]

    def ask_llm(self, query: str, chunks: List[Dict]):
        if not chunks: return "æœªæ‰¾åˆ°ç›¸å…³å‚è€ƒèµ„æ–™ã€‚"

        context = ""
        for i, c in enumerate(chunks):
            context += f"èµ„æ–™[{i+1}] (æ¥æº: {c['section_title']}):\n{c['raw_content']}\n\n"

        prompt = f"ä½ æ˜¯ Zeek ä¸“å®¶ã€‚è¯·æ ¹æ®èµ„æ–™å›ç­”é—®é¢˜ã€‚èµ„æ–™æŒ‰ç›¸å…³æ€§æ’åºã€‚\nèµ„æ–™ï¼š\n{context}\né—®é¢˜ï¼š{query}\nå›ç­”ï¼š"

        try:
            r = requests.post(f"{OLLAMA_HOST}/api/generate",
                              json={"model": LLM_MODEL, "prompt": prompt, "stream": False}, timeout=60)
            return r.json().get("response", "ç”Ÿæˆå¤±è´¥")
        except: return "LLM æœåŠ¡è¶…æ—¶"

    def chat(self, query: str):
        print(f"\né—®: {query}")
        hits = self.retrieve(query)
        top = self.rerank_with_bge(query, hits)
        ans = self.ask_llm(query, top)

        print(f"ğŸ¤– Zeek AI:\n{ans}")
        print("-" * 30)
        for i, c in enumerate(top):
            print(f"Top {i+1}: {c['section_title']} (Score: {c['final_score']:.2f})")


# ===================== æµ‹è¯•æ‰§è¡Œ =====================
if __name__ == "__main__":
    assistant = ZeekRAGAssistant()

    # æµ‹è¯•ç”¨ä¾‹
    # test_queries = [
    #     "å½“å‰zeekç‰ˆæœ¬å·",
    #     "what is zeek?",
    #     "Zeek æ˜¯ä»€ä¹ˆï¼Ÿ",
    #     "ä»‹ç»ä¸€ä¸‹ Zeek çš„æ ¸å¿ƒåŠŸèƒ½",
    #     "Zeek å’Œ Suricata çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    #     "zeek_init å’Œ zeek_done å‡½æ•°çš„åŒºåˆ«",
    #     "å¦‚ä½•ç”¨ Zeek è„šæœ¬æå– HTTP è¯·æ±‚çš„ URLï¼Ÿ",
    #     "Zeek SSL æ—¥å¿—ä¸­çš„ client_cert å­—æ®µå«ä¹‰",
    #     "Zeek æ”¯æŒ Python 3.10 å—ï¼Ÿ",
    # ]

    test_queries = [
        "å†™ä¸€ä¸ªzeek8.0.4ç‰ˆæœ¬åˆ†æpcapæ–‡ä»¶ä¸­ddosæ”»å‡»çš„zeekè„šæœ¬",
    ]

    # æ‰§è¡Œæµ‹è¯•
    for query in test_queries:
        try:
            assistant.chat(query)
        except Exception as e:
            logging.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥ '{query}': {str(e)}")
            print(f"\nâŒ å¤„ç†å¤±è´¥: {str(e)}\n")